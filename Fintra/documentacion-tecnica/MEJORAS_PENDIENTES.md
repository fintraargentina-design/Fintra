# Mejoras y Optimizaciones Pendientes - Fintra

**Fecha de auditorÃ­a:** 6 de febrero, 2026  
**Ãšltima actualizaciÃ³n:** 6 de febrero, 2026

Este documento identifica oportunidades de mejora, optimizaciones tÃ©cnicas y actualizaciones recomendadas para el sistema Fintra, organizadas por prioridad y Ã¡rea.

---

## ğŸ“‹ Resumen Ejecutivo

| CategorÃ­a    | Mejoras Identificadas | Impacto Estimado | Esfuerzo    |
| ------------ | --------------------- | ---------------- | ----------- |
| Performance  | 8 mejoras             | ğŸ”´ Alto          | 2-4 semanas |
| Arquitectura | 5 mejoras             | ğŸŸ¡ Medio         | 3-6 semanas |
| CÃ³digo       | 12 mejoras            | ğŸŸ¡ Medio         | 1-2 semanas |
| Seguridad    | 3 mejoras             | ğŸ”´ Alto          | 1 semana    |
| DevOps       | 4 mejoras             | ğŸŸ¢ Bajo          | 1-2 semanas |
| Testing      | 6 mejoras             | ğŸŸ¡ Medio         | 2-3 semanas |

**Total:** 38 mejoras identificadas

---

## ğŸ”´ PRIORIDAD CRÃTICA - Impacto Alto / Riesgo Alto

### 1. Seguridad: Credenciales Hardcodeadas

**Archivo:** `temp-audit-financial.js`

**Problema:**

```javascript
const supabase = createClient(
  "https://lvqfmrsvtyoemxfbnwzv.supabase.co",
  "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...", // SERVICE_ROLE_KEY expuesto
);
```

**Impacto:** ğŸ”´ **CRÃTICO**

- Service role key comprometido
- Acceso ilimitado a base de datos
- ViolaciÃ³n de mejores prÃ¡cticas de seguridad

**SoluciÃ³n:**

1. **ROTAR** inmediatamente el service role key en Supabase Dashboard
2. Eliminar archivo `temp-audit-financial.js`
3. Agregar hook pre-commit para detectar secrets: `gitleaks` o `trufflehog`
4. Auditar repositorio con `git-secrets` para verificar histÃ³rico

**Esfuerzo:** 2 horas  
**Prioridad:** ğŸ”´ INMEDIATA

---

### 2. Performance: TTM Parsing Deshabilitado

**Archivo:** `app/api/cron/financials-bulk/core.ts`

**Problema:**

```typescript
// TEMP: Skip TTM downloads/parsing due to timeout issues
// TODO: Investigate TTM parsing performance issue
// tasks.push(fetchFile("key-metrics-ttm-bulk", null, null));
// tasks.push(fetchFile("ratios-ttm-bulk", null, null));
```

**Impacto:** ğŸ”´ **ALTO**

- MÃ©tricas TTM no se estÃ¡n actualizando desde FMP bulk files
- Dependencia en endpoint individual `/key-metrics/TICKER?period=ttm` (mÃ¡s lento)
- Inconsistencia de datos entre fuentes

**AnÃ¡lisis de Causa RaÃ­z:**
Los archivos TTM bulk son Ãºnicos (no agrupados por aÃ±o/periodo), conteniendo ~50,000 rows con todos los tickers. El problema probablemente es:

1. Parser bloqueando event loop al procesar archivo masivo
2. Memory spike al cargar todo el archivo antes de filtrar

**SoluciÃ³n Propuesta:**

```typescript
// Implementar streaming chunked para TTM files
const parseFileTTMOptimized = async (endpoint: string) => {
  const filePath = path.join(CACHE_DIR, `${endpoint}.csv`);
  const CHUNK_SIZE = 5000; // Procesar en chunks

  return new Promise((resolve) => {
    const results: any[] = [];
    let buffer: any[] = [];

    Papa.parse(createReadStream(filePath), {
      header: true,
      step: (row) => {
        if (activeTickers.has(row.data.symbol)) {
          buffer.push(row.data);
        }

        // Procesar chunks para evitar bloqueo
        if (buffer.length >= CHUNK_SIZE) {
          results.push(...buffer);
          buffer = [];
          setImmediate(() => {}); // Yield event loop
        }
      },
      complete: () => {
        results.push(...buffer);
        resolve(results);
      },
    });
  });
};
```

**Beneficios:**

- âœ… Reactiva TTM bulk processing (mÃ¡s rÃ¡pido que API individual)
- âœ… Mantiene memoria constante
- âœ… Evita timeouts

**Esfuerzo:** 4-6 horas  
**Prioridad:** ğŸ”´ ALTA

---

### 3. Architecture: Implementar Verbose Logging Control

**Status:** âœ… **PARCIALMENTE IMPLEMENTADO** (solo en financials-bulk)

**Problema:**

- Solo `financials-bulk` tiene parÃ¡metro `verbose`
- Otros 15+ crons tienen logging hardcoded
- Logs de producciÃ³n contaminados con debug info
- Dificulta troubleshooting (no se puede activar verbose on-demand)

**SoluciÃ³n:**

```typescript
// lib/utils/logger.ts (NUEVO)
export class CronLogger {
  private verbose: boolean;
  private prefix: string;

  constructor(cronName: string, verbose: boolean = false) {
    this.verbose = verbose;
    this.prefix = `[${cronName}]`;
  }

  debug(...args: any[]) {
    if (this.verbose) console.log(this.prefix, ...args);
  }

  info(...args: any[]) {
    console.log(this.prefix, ...args);
  }

  warn(...args: any[]) {
    console.warn(this.prefix, ...args);
  }

  error(...args: any[]) {
    console.error(this.prefix, ...args);
  }
}

// Uso en cada cron:
export async function runPricesDailyBulk(opts: { verbose?: boolean }) {
  const logger = new CronLogger("prices-daily", opts.verbose);

  logger.info("Starting...");
  logger.debug("Processing ticker:", ticker); // Solo si verbose=true
  logger.error("Failed:", error);
}
```

**Beneficios:**

- âœ… Control granular de logging por cron
- âœ… Logs de producciÃ³n limpios
- âœ… Debug on-demand para troubleshooting
- âœ… FÃ¡cil agregar file logging o external services (Sentry, Datadog)

**Esfuerzo:** 1-2 dÃ­as  
**Prioridad:** ğŸŸ¡ MEDIA-ALTA

---

### 4. Performance: Optimizar `valuation-bulk` con Streaming

**Archivo:** `app/api/cron/valuation-bulk/core.ts`

**Problema Actual:**

```typescript
// Carga archivos completos en memoria
const ratiosData = await fs.readFile(ratiosFile, "utf-8");
const metricsData = await fs.readFile(metricsFile, "utf-8");
const profileData = await fs.readFile(profileFile, "utf-8");

// Parse sincrÃ³nicamente bloqueando event loop
const ratios = Papa.parse(ratiosData, { header: true }).data;
```

**Impacto:** ğŸŸ¡ MEDIO

- Memory spike de ~150 MB durante peak
- Event loop bloqueado durante parsing
- Escalabilidad limitada si archivos crecen

**SoluciÃ³n:**

```typescript
// Migrar a streaming pattern (similar a financials-bulk)
const parseFileStreaming = async (
  filePath: string,
  activeTickers: Set<string>,
) => {
  return new Promise((resolve) => {
    const rows: any[] = [];
    const stream = createReadStream(filePath);

    Papa.parse(stream, {
      header: true,
      dynamicTyping: true,
      step: (result) => {
        const symbol = result.data.symbol || result.data.ticker;
        if (activeTickers.has(symbol)) {
          rows.push(result.data);
        }
      },
      complete: () => resolve(rows),
    });
  });
};
```

**Beneficios:**

- âœ… Memoria constante (~50 MB)
- âœ… No bloquea event loop
- âœ… Filtrado durante parsing (mÃ¡s eficiente)

**Esfuerzo:** 4 horas  
**Prioridad:** ğŸŸ¡ MEDIA

---

## ğŸŸ¡ PRIORIDAD ALTA - Impacto Medio / Quick Wins

### 5. Code Quality: Implementar Pre-commit Hooks

**Problema:**

- No hay validaciÃ³n automÃ¡tica de cÃ³digo antes de commits
- Archivos `.log`, `.backup` llegan a git
- Credenciales pueden filtrarse accidentalmente

**SoluciÃ³n:**

```bash
# Instalar Husky
pnpm add -D husky lint-staged

# .husky/pre-commit
#!/bin/sh
. "$(dirname "$0")/_/husky.sh"

# 1. Lint staged files
pnpm lint-staged

# 2. Check for secrets
gitleaks protect --staged

# 3. Run type check on changed files
pnpm tsc --noEmit
```

```json
// package.json
{
  "lint-staged": {
    "*.{ts,tsx}": ["eslint --fix", "prettier --write"],
    "*.md": ["prettier --write"]
  }
}
```

**Beneficios:**

- âœ… Previene commits con errores
- âœ… Detecta secrets antes de push
- âœ… Code style consistente
- âœ… Reduce code review time

**Esfuerzo:** 2 horas  
**Prioridad:** ğŸŸ¡ ALTA

---

### 6. DevOps: Implementar Healthcheck Endpoint

**Problema:**

- No hay forma programÃ¡tica de verificar salud del sistema
- Monitoreo manual de logs
- Dificulta implementar alertas automÃ¡ticas

**SoluciÃ³n:**

```typescript
// app/api/health/route.ts
export async function GET() {
  const checks = await Promise.allSettled([
    checkDatabase(),
    checkFMPApi(),
    checkSupabase(),
    checkLastCronRun(),
  ]);

  const healthy = checks.every((c) => c.status === "fulfilled");
  const status = healthy ? 200 : 503;

  return Response.json(
    {
      status: healthy ? "healthy" : "degraded",
      timestamp: new Date().toISOString(),
      checks: {
        database: checks[0].status === "fulfilled" ? "ok" : "error",
        fmpApi: checks[1].status === "fulfilled" ? "ok" : "error",
        supabase: checks[2].status === "fulfilled" ? "ok" : "error",
        lastCron: checks[3].status === "fulfilled" ? "ok" : "error",
      },
    },
    { status },
  );
}

async function checkLastCronRun() {
  const { data } = await supabaseAdmin
    .from("cron_execution_log")
    .select("*")
    .order("executed_at", { ascending: false })
    .limit(1)
    .single();

  const hoursSinceLastRun =
    (Date.now() - new Date(data.executed_at).getTime()) / (1000 * 60 * 60);

  if (hoursSinceLastRun > 25) {
    throw new Error("Cron not running in last 25 hours");
  }
}
```

**Beneficios:**

- âœ… Monitoreo automÃ¡tico con UptimeRobot/Pingdom
- âœ… Alertas cuando algo falla
- âœ… Dashboard de salud del sistema
- âœ… Debug mÃ¡s rÃ¡pido

**Esfuerzo:** 4 horas  
**Prioridad:** ğŸŸ¡ ALTA

---

### 7. Performance: Implementar Cron Execution Locking

**Problema Actual:**

- Si un cron se ejecuta manualmente mientras el scheduled corre, puede haber:
  - Duplicate processing
  - Race conditions en DB
  - Recursos desperdiciados

**SoluciÃ³n:**

```typescript
// Ya existe en lib/utils/dbLocks.ts pero NO SE USA en todos los crons

// Ejemplo de implementaciÃ³n:
export async function runFinancialsBulk(...args, runId?: string) {
  const lockName = "financials-bulk";

  return await withDbLock(lockName, async () => {
    console.log(`ğŸ”’ Lock acquired: ${lockName}`);

    // Procesar...
    const result = await processFinancials(...args);

    console.log(`ğŸ”“ Releasing lock: ${lockName}`);
    return result;
  });
}
```

**AcciÃ³n:**

- âœ… `withDbLock()` ya existe en `lib/utils/dbLocks.ts`
- âŒ Solo 2-3 crons lo estÃ¡n usando
- ğŸ”§ Implementar en TODOS los crons del master pipeline

**Beneficios:**

- âœ… Previene ejecuciones concurrentes
- âœ… Evita race conditions
- âœ… Logs mÃ¡s claros (se ve cuando un cron estÃ¡ locked)

**Esfuerzo:** 4 horas (wrap cada cron)  
**Prioridad:** ğŸŸ¡ MEDIA-ALTA

---

### 8. Architecture: Crear Tabla de Cron Execution History

**Problema:**

- No hay registro histÃ³rico de ejecuciones de crons
- Debugging requiere analizar logs manualmente
- No hay mÃ©tricas de performance trend

**SoluciÃ³n:**

```sql
-- supabase/migrations/YYYYMMDDHHMMSS_cron_execution_log.sql
CREATE TABLE IF NOT EXISTS cron_execution_log (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  cron_name TEXT NOT NULL,
  started_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  completed_at TIMESTAMPTZ,
  status TEXT NOT NULL CHECK (status IN ('running', 'success', 'failed')),
  duration_seconds INTEGER,
  tickers_processed INTEGER,
  rows_affected INTEGER,
  error_message TEXT,
  metadata JSONB DEFAULT '{}'::jsonb
);

CREATE INDEX idx_cron_log_name_started ON cron_execution_log(cron_name, started_at DESC);
CREATE INDEX idx_cron_log_status ON cron_execution_log(status);
```

```typescript
// lib/utils/cronLogger.ts
export class CronExecutionTracker {
  private logId: string;

  async start(cronName: string, metadata: any = {}) {
    const { data } = await supabaseAdmin
      .from('cron_execution_log')
      .insert({
        cron_name: cronName,
        status: 'running',
        metadata
      })
      .select()
      .single();

    this.logId = data.id;
  }

  async complete(stats: { tickersProcessed: number, rowsAffected: number }) {
    await supabaseAdmin
      .from('cron_execution_log')
      .update({
        completed_at: new Date().toISOString(),
        status: 'success',
        duration_seconds: ...,
        tickers_processed: stats.tickersProcessed,
        rows_affected: stats.rowsAffected
      })
      .eq('id', this.logId);
  }
}
```

**Beneficios:**

- âœ… Dashboard de ejecuciones en Supabase
- âœ… Alertas basadas en duraciÃ³n/failures
- âœ… MÃ©tricas de performance trend
- âœ… Debugging mÃ¡s rÃ¡pido

**Esfuerzo:** 6 horas  
**Prioridad:** ğŸŸ¡ MEDIA

---

### 9. Testing: Implementar Unit Tests para Financial Logic

**Problema:**

- Zero unit tests para lÃ³gica financiera crÃ­tica
- Cambios pueden romper cÃ¡lculos sin darse cuenta
- Regression bugs frecuentes

**SoluciÃ³n:**

```typescript
// __tests__/financial-metrics.test.ts
describe("deriveFinancialMetrics", () => {
  it("calcula ROIC correctamente", () => {
    const income = { netIncome: 1000, revenue: 10000 };
    const balance = { totalAssets: 20000, totalLiabilities: 8000 };

    const metrics = deriveFinancialMetrics(income, balance, {});

    expect(metrics.roic).toBeCloseTo(0.0833, 2); // 1000 / 12000 = 8.33%
  });

  it("retorna null cuando faltan datos", () => {
    const metrics = deriveFinancialMetrics(null, null, {});
    expect(metrics.roic).toBeNull();
  });

  it("no inventa datos cuando revenue es 0", () => {
    const income = { netIncome: 100, revenue: 0 };
    const metrics = deriveFinancialMetrics(income, {}, {});

    expect(metrics.net_margin).toBeNull(); // NO Infinity
  });
});
```

**Ãreas CrÃ­ticas para Testing:**

1. âœ… `deriveFinancialMetrics.ts` - CÃ¡lculos de mÃ©tricas
2. âœ… `fintra-brain.ts` (FGOS) - Scoring logic
3. âœ… TTM construction - Suma de quarters
4. âœ… Percentile calculations - Benchmarks
5. âœ… Temporal consistency - Look-ahead bias prevention

**Esfuerzo:** 2-3 dÃ­as  
**Prioridad:** ğŸŸ¡ MEDIA-ALTA

---

### 10. Performance: Batch Upsert Optimization para PequeÃ±os Crons

**Problema:**
Crons como `industry-performance-aggregator` hacen upserts individuales:

```typescript
for (const industry of industries) {
  const perf = await calculatePerformance(industry);
  await supabase.from("industry_performance").upsert(perf); // âŒ N round-trips
}
```

**SoluciÃ³n:**

```typescript
// Batch todas las operaciones
const performances = await Promise.all(
  industries.map((ind) => calculatePerformance(ind)),
);

await supabase.from("industry_performance").upsert(performances); // âœ… 1 round-trip
```

**Crons Afectados:**

- `industry-performance-aggregator` (~150 rows)
- `sector-performance-aggregator` (~11 rows)
- `industry-pe-aggregator` (~150 rows)
- `sector-pe-aggregator` (~11 rows)

**Beneficios:**

- âœ… 150x menos round-trips
- âœ… 5-10x mÃ¡s rÃ¡pido
- âœ… Menos carga en DB

**Esfuerzo:** 2 horas  
**Prioridad:** ğŸŸ¡ MEDIA

---

## ğŸŸ¢ PRIORIDAD MEDIA - Refactoring y Mejoras de Calidad

### 11. Code Quality: Estandarizar Error Handling

**Problema:**

- Inconsistencia en manejo de errores entre crons
- Algunos lanzan exceptions, otros retornan null
- Dificulta debugging y monitoreo centralizado

**SituaciÃ³n Actual:**

```typescript
// financials-bulk: fault-tolerant loop
for (const ticker of tickers) {
  try {
    await process(ticker);
  } catch (e) {
    console.error(`Failed ${ticker}:`, e);
    // ContinÃºa con siguiente ticker âœ…
  }
}

// prices-daily-bulk: fail-fast
for (const ticker of tickers) {
  await process(ticker); // âŒ Primer error aborta todo
}
```

**SoluciÃ³n:**

```typescript
// lib/utils/cronHelpers.ts
export async function processBatchFaultTolerant<T>(
  items: T[],
  processor: (item: T) => Promise<any>,
  onError?: (item: T, error: Error) => void,
) {
  const results = {
    succeeded: [] as T[],
    failed: [] as { item: T; error: Error }[],
  };

  for (const item of items) {
    try {
      await processor(item);
      results.succeeded.push(item);
    } catch (error) {
      results.failed.push({ item, error });
      onError?.(item, error);
    }
  }

  return results;
}

// Uso:
const { succeeded, failed } = await processBatchFaultTolerant(
  tickers,
  async (ticker) => await processFinancials(ticker),
  (ticker, error) => console.error(`${ticker} failed:`, error),
);

console.log(`âœ… Processed: ${succeeded.length}, âŒ Failed: ${failed.length}`);
```

**Beneficios:**

- âœ… Comportamiento consistente
- âœ… Mejor visibilidad de errores
- âœ… FÃ¡cil agregar retry logic
- âœ… MÃ©tricas de success rate

**Esfuerzo:** 1 dÃ­a  
**Prioridad:** ğŸŸ¢ MEDIA

---

### 12. Architecture: Implementar Rate Limiting para FMP API

**Problema:**

- FMP API tiene rate limits (429 errors frecuentes)
- No hay exponential backoff
- No hay circuit breaker pattern

**SoluciÃ³n:**

```typescript
// lib/fmp/rateLimiter.ts
import pLimit from "p-limit";

const limiter = pLimit(5); // Max 5 concurrent requests
const requestQueue: Array<() => Promise<any>> = [];

export async function fmpGetWithRateLimit(endpoint: string) {
  return limiter(async () => {
    let retries = 3;
    let delay = 1000;

    while (retries > 0) {
      try {
        const response = await fetch(endpoint);

        if (response.status === 429) {
          retries--;
          await sleep(delay);
          delay *= 2; // Exponential backoff
          continue;
        }

        if (!response.ok) {
          throw new Error(`FMP error: ${response.status}`);
        }

        return response.json();
      } catch (error) {
        if (retries === 0) throw error;
        retries--;
        await sleep(delay);
      }
    }
  });
}
```

**Beneficios:**

- âœ… Menos 429 errors
- âœ… Retry automÃ¡tico inteligente
- âœ… No satura API
- âœ… Mejor confiabilidad

**Esfuerzo:** 4 horas  
**Prioridad:** ğŸŸ¢ MEDIA

---

### 13. DevOps: Implementar Rollbar/Sentry para Error Tracking

**Problema:**

- Errores solo en logs locales
- No hay agregaciÃ³n de errores
- No hay alertas automÃ¡ticas
- DifÃ­cil identificar patterns

**SoluciÃ³n:**

```typescript
// lib/utils/errorTracker.ts
import * as Sentry from "@sentry/nextjs";

Sentry.init({
  dsn: process.env.SENTRY_DSN,
  environment: process.env.NODE_ENV,
  tracesSampleRate: 0.1,

  beforeSend(event) {
    // Sanitizar datos sensibles
    if (event.request?.headers) {
      delete event.request.headers["authorization"];
    }
    return event;
  },
});

export function captureException(error: Error, context?: any) {
  Sentry.captureException(error, {
    extra: context,
  });
  console.error(error); // Keep console logging
}

// Uso en crons:
try {
  await processFinancials(ticker);
} catch (error) {
  captureException(error, { ticker, cronName: "financials-bulk" });
}
```

**Beneficios:**

- âœ… Dashboard centralizado de errores
- âœ… Alertas en Slack/Email automÃ¡ticas
- âœ… Stack traces completos
- âœ… Identifica errores recurrentes

**Esfuerzo:** 3 horas  
**Prioridad:** ğŸŸ¢ MEDIA

---

### 14. Database: Implementar Materialized Views para Queries Lentas

**Problema:**

- Queries de sector benchmarks calculados on-demand
- Dashboard carga lento (joins pesados)
- Mismas agregaciones recalculadas mÃºltiples veces

**SoluciÃ³n:**

```sql
-- Materialized view para sector stats
CREATE MATERIALIZED VIEW sector_stats_current AS
SELECT
  sector,
  COUNT(*) as company_count,
  AVG(market_cap) as avg_market_cap,
  PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY pe_ratio) as median_pe,
  AVG(revenue_growth_yoy) as avg_revenue_growth
FROM fintra_market_state
WHERE snapshot_date = CURRENT_DATE
GROUP BY sector;

CREATE UNIQUE INDEX ON sector_stats_current(sector);

-- Refresh automÃ¡tico con pg_cron
SELECT cron.schedule(
  'refresh-sector-stats',
  '0 1 * * *', -- 1 AM diario
  'REFRESH MATERIALIZED VIEW CONCURRENTLY sector_stats_current'
);
```

**Views Recomendadas:**

1. âœ… `sector_stats_current` - Stats por sector
2. âœ… `industry_stats_current` - Stats por industria
3. âœ… `top_performers_1d` - Top gainers/losers
4. âœ… `fgos_distribution` - DistribuciÃ³n de FGOS scores

**Beneficios:**

- âœ… Dashboard 10-20x mÃ¡s rÃ¡pido
- âœ… Menos carga en DB
- âœ… Queries simples vs complejos joins

**Esfuerzo:** 1 dÃ­a  
**Prioridad:** ğŸŸ¢ MEDIA

---

### 15. Frontend: Implementar Stale-While-Revalidate Pattern

**Problema:**

- Cada request va a DB/API
- No hay caching en cliente
- Datos "en vivo" no necesarios para todo

**SoluciÃ³n:**

```typescript
// hooks/useSWR.ts (usando SWR library)
import useSWR from "swr";

export function useStockData(ticker: string) {
  const { data, error, mutate } = useSWR(`/api/stock/${ticker}`, fetcher, {
    revalidateOnFocus: false,
    revalidateOnReconnect: false,
    refreshInterval: 60000, // Refresh cada 60s
    dedupingInterval: 30000, // Dedupe requests en 30s window
  });

  return {
    stock: data,
    isLoading: !error && !data,
    isError: error,
    refresh: mutate,
  };
}
```

**Beneficios:**

- âœ… UX mÃ¡s rÃ¡pida (muestra cached data inmediatamente)
- âœ… Menos carga en backend
- âœ… Auto-refresh en background
- âœ… Optimistic updates

**Esfuerzo:** 1 dÃ­a  
**Prioridad:** ğŸŸ¢ BAJA-MEDIA

---

### 16. Testing: Implementar E2E Tests con Playwright

**Problema:**

- Zero tests end-to-end
- Regresiones en UI no detectadas hasta producciÃ³n
- Testing manual consume tiempo

**SoluciÃ³n:**

```typescript
// e2e/stock-detail.spec.ts
import { test, expect } from "@playwright/test";

test("Stock detail page loads correctly", async ({ page }) => {
  await page.goto("/resumen/AAPL");

  // Verifica que cargue
  await expect(page.locator("h1")).toContainText("Apple");

  // Verifica que muestre FGOS
  const fgosCard = page.locator('[data-testid="fgos-card"]');
  await expect(fgosCard).toBeVisible();

  // Verifica que grÃ¡ficos rendericen
  const chart = page.locator("canvas");
  await expect(chart).toBeVisible();
});

test("Search functionality works", async ({ page }) => {
  await page.goto("/");
  await page.fill('[data-testid="search-input"]', "AAPL");
  await page.click('[data-testid="search-result"]:first-child');

  await expect(page).toHaveURL("/resumen/AAPL");
});
```

**Tests CrÃ­ticos:**

1. âœ… Stock search â†’ detail page
2. âœ… FGOS card rendering
3. âœ… Financial charts display
4. âœ… Sector comparison table
5. âœ… Tab navigation

**Esfuerzo:** 2 dÃ­as  
**Prioridad:** ğŸŸ¢ MEDIA

---

### 17. Performance: Implementar CDN para Assets EstÃ¡ticos

**Problema:**

- Logos, Ã­conos servidos desde Next.js server
- No hay caching agresivo
- TTFB mÃ¡s lento para usuarios lejos del server

**SoluciÃ³n:**

```javascript
// next.config.mjs
export default {
  images: {
    loader: "cloudinary", // o 'cloudflare'
    path: "https://fintra.cdn.com/",
  },

  async headers() {
    return [
      {
        source: "/logos/:path*",
        headers: [
          {
            key: "Cache-Control",
            value: "public, max-age=31536000, immutable",
          },
        ],
      },
    ];
  },
};
```

**Assets para CDN:**

- `/public/logos/` - Logos de companies (~500 files)
- `/public/icons/` - Ãconos UI
- Fonts custom (si existen)
- CSS/JS bundles (Next.js hace auto)

**Beneficios:**

- âœ… 50-200ms menos TTFB
- âœ… Menor carga en VPS
- âœ… Edge caching global
- âœ… Mejor Core Web Vitals

**Esfuerzo:** 4 horas  
**Prioridad:** ğŸŸ¢ BAJA

---

## ğŸ”µ PRIORIDAD BAJA - Nice to Have

### 18. Code Quality: Migrar a TypeScript Strict Mode

**Problema:**

```json
// tsconfig.json actual
{
  "strict": true, // âœ… Ya estÃ¡ activado
  "strictNullChecks": true
}
```

**Status:** âœ… **YA IMPLEMENTADO**

---

### 19. DevOps: Implementar Docker para Dev Environment

**Problema:**

- Setup manual de dependencias
- Inconsistencias entre dev/prod
- Onboarding de nuevos devs lento

**SoluciÃ³n:**

```dockerfile
# Dockerfile
FROM node:20-alpine

WORKDIR /app

# Install pnpm
RUN npm install -g pnpm

# Copy dependency files
COPY package.json pnpm-lock.yaml ./
RUN pnpm install --frozen-lockfile

# Copy source
COPY . .

# Build
RUN pnpm build

EXPOSE 3000
CMD ["pnpm", "start"]
```

```yaml
# docker-compose.yml
version: "3.8"
services:
  app:
    build: .
    ports:
      - "3000:3000"
    env_file: .env
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
```

**Beneficios:**

- âœ… Setup en 5 minutos
- âœ… Ambiente consistente
- âœ… FÃ¡cil deployment

**Esfuerzo:** 4 horas  
**Prioridad:** ğŸ”µ BAJA

---

### 20. Documentation: Crear API Documentation con Swagger

**Problema:**

- No hay documentaciÃ³n de API endpoints
- Developers deben leer cÃ³digo para integrar

**SoluciÃ³n:**

```typescript
// app/api/docs/route.ts
import { createSwaggerSpec } from "next-swagger-doc";

const spec = createSwaggerSpec({
  apiFolder: "app/api",
  definition: {
    openapi: "3.0.0",
    info: {
      title: "Fintra API",
      version: "1.0.0",
    },
  },
});

export async function GET() {
  return Response.json(spec);
}
```

**Endpoints a Documentar:**

1. `/api/stock/[ticker]` - Stock data
2. `/api/search` - Search tickers
3. `/api/sector/[sector]` - Sector stats
4. `/api/health` - System health

**Beneficios:**

- âœ… DocumentaciÃ³n auto-generada
- âœ… Playground interactivo
- âœ… FÃ¡cil integraciÃ³n para terceros

**Esfuerzo:** 1 dÃ­a  
**Prioridad:** ğŸ”µ BAJA

---

## ğŸ“Š Roadmap Sugerido

### Q1 2026 (Feb-Mar)

**Sprint 1 (Semana 1-2):**

- ğŸ”´ Rotar credenciales expuestas
- ğŸ”´ Implementar verbose logging en todos crons
- ğŸŸ¡ Pre-commit hooks
- ğŸŸ¡ Healthcheck endpoint

**Sprint 2 (Semana 3-4):**

- ğŸ”´ Fix TTM parsing con streaming
- ğŸŸ¡ Cron execution locking
- ğŸŸ¡ Cron execution history table
- ğŸŸ¢ Batch upsert optimization

### Q2 2026 (Apr-Jun)

**Sprint 3:**

- ğŸŸ¡ Unit tests para financial logic
- ğŸŸ¡ Rate limiting para FMP API
- ğŸŸ¢ Error tracking (Sentry)

**Sprint 4:**

- ğŸŸ¢ Materialized views
- ğŸŸ¢ E2E tests
- ğŸŸ¢ CDN para assets

### Q3 2026 (Jul-Sep)

**Sprint 5:**

- ğŸŸ¢ Docker setup
- ğŸ”µ API documentation
- ğŸ”µ Frontend SWR pattern

---

## ğŸ“ˆ MÃ©tricas de Ã‰xito

### Performance

- âœ… Crons diarios < 30 minutos (actualmente ~45 min)
- âœ… Dashboard load time < 2 segundos (actualmente ~5s)
- âœ… API response time p95 < 500ms

### Confiabilidad

- âœ… Cron success rate > 99%
- âœ… Zero critical errors en 30 dÃ­as
- âœ… Uptime > 99.9%

### Code Quality

- âœ… Test coverage > 70%
- âœ… Zero security vulnerabilities
- âœ… TypeScript strict mode: 100%

---

## ğŸ”— Referencias

- Ver tambiÃ©n: `CODIGO_DEPRECADO.md` para limpieza de cÃ³digo
- Ver: `CRON_OPTIMIZATION_LOG.md` para estado actual
- Ver: `PARALLELIZATION_PATTERNS.md` para patrones de performance

---

**Ãšltima RevisiÃ³n:** 6 de febrero, 2026  
**PrÃ³xima RevisiÃ³n Programada:** 6 de abril, 2026
