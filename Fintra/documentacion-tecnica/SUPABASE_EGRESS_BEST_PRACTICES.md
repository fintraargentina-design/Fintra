# Supabase Egress Best Practices

> **CR√çTICO:** El egress (data transfer out) es el mayor costo variable en Supabase. Una query sin optimizar puede generar GBs de egress sin advertencia.

---

## Principios Fundamentales

### 1. SIEMPRE Usar LIMIT en Queries Bulk

```typescript
// ‚ùå PROHIBIDO - Sin limit
const { data } = await supabase
  .from("large_table")
  .select("*")
  .order("date", { ascending: false });

// ‚úÖ CORRECTO - Con limit expl√≠cito
const { data } = await supabase
  .from("large_table")
  .select("field1, field2, field3")
  .order("date", { ascending: false })
  .limit(1000); // M√°ximo esperado
```

**Raz√≥n:** Supabase NO limita autom√°ticamente. Una tabla con 1M rows retornar√° 1M rows si no especificas limit.

---

### 2. Filtrar por Fecha Actual en Tablas Temporales

```typescript
// ‚ùå PROBLEMA - Lee toda la historia
const { data } = await supabase
  .from("performance_windows")
  .select("*")
  .lte("as_of_date", today);
// Retorna: 53k tickers √ó 7 windows √ó 365 d√≠as = 135M rows

// ‚úÖ MEJOR - Solo fecha actual
const { data } = await supabase
  .from("performance_windows")
  .select("ticker, window_code, return_value")
  .eq("as_of_date", today);
// Retorna: 53k √ó 7 = 371k rows (365√ó reducci√≥n)
```

**Raz√≥n:** Tablas con historial temporal crecen exponencialmente. Siempre filtrar por fecha cuando sea posible.

---

### 3. Select Solo Campos Necesarios

```typescript
// ‚ùå PROBLEMA
const { data } = await supabase
  .from("datos_financieros")
  .select("*")
  .in("ticker", tickers);
// Retorna: ~40 campos √ó N rows

// ‚úÖ MEJOR
const { data } = await supabase
  .from("datos_financieros")
  .select("ticker, period_end_date, revenue, net_income, roic")
  .in("ticker", tickers)
  .limit(5000);
// Retorna: 5 campos √ó MAX 5k rows
```

**Raz√≥n:** Cada campo adicional multiplica el egress. `select('*')` puede triplicar el tama√±o vs select espec√≠fico.

---

### 4. Usar `head: true` para Counts

```typescript
// ‚ùå PROBLEMA - Retorna data
const { data } = await supabase.from("huge_table").select("*");
const count = data.length;

// ‚úÖ CORRECTO - Solo count, sin data
const { count } = await supabase
  .from("huge_table")
  .select("*", { count: "exact", head: true });
// head: true ‚Üí NO retorna rows, solo count metadata
```

**Raz√≥n:** `head: true` usa HTTP HEAD request. No transfiere data, solo metadata.

---

### 5. Paginar Queries Grandes Expl√≠citamente

```typescript
// ‚ùå PROBLEMA - Asume paginaci√≥n autom√°tica
const { data } = await supabase
  .from("fintra_universe")
  .select("ticker, sector");
// PostgREST trunca silenciosamente a 1000 rows

// ‚úÖ CORRECTO - Paginaci√≥n expl√≠cita
const PAGE_SIZE = 1000;
const allRows = [];
let page = 0;
let hasMore = true;

while (hasMore) {
  const from = page * PAGE_SIZE;
  const to = from + PAGE_SIZE - 1;

  const { data } = await supabase
    .from("fintra_universe")
    .select("ticker, sector")
    .range(from, to)
    .order("ticker", { ascending: true });

  allRows.push(...data);
  hasMore = data.length === PAGE_SIZE;
  page++;
}
```

**Raz√≥n:** PostgREST tiene l√≠mite server-side (~1000 rows). Si necesitas m√°s, DEBES paginar expl√≠citamente.

---

## Patrones de Queries Optimizadas

### Pattern 1: Bulk Fetch con L√≠mite Expl√≠cito

```typescript
export async function fetchRecentData(
  supabase: SupabaseClient,
  tickers: string[],
  maxRecordsPerTicker: number = 20,
) {
  if (!tickers.length) return new Map();

  const TOTAL_LIMIT = tickers.length * maxRecordsPerTicker;

  const { data, error } = await supabase
    .from("datos_financieros")
    .select("ticker, period_end_date, revenue, net_income")
    .in("ticker", tickers)
    .order("period_end_date", { ascending: false })
    .limit(TOTAL_LIMIT); // Expl√≠cito

  return groupByTicker(data);
}
```

### Pattern 2: Date-Filtered Aggregates

```typescript
export async function fetchTodayPerformance(
  supabase: SupabaseClient,
  asOfDate: string,
) {
  const { data } = await supabase
    .from("performance_windows")
    .select("ticker, window_code, return_value")
    .eq("as_of_date", asOfDate) // Filtro cr√≠tico
    .order("ticker", { ascending: true });

  return data; // ~371k rows (vs 135M sin filtro)
}
```

### Pattern 3: Cached Reference Data

```typescript
// Cache en memoria para datos de referencia
let cachedUniverse: Map<string, any> | null = null;
let cacheTimestamp = 0;
const CACHE_TTL_MS = 1000 * 60 * 60; // 1 hora

export async function getUniverseMap(supabase: SupabaseClient) {
  const now = Date.now();

  if (cachedUniverse && now - cacheTimestamp < CACHE_TTL_MS) {
    console.log("[CACHE HIT] Using cached universe");
    return cachedUniverse;
  }

  // Fetch con paginaci√≥n
  cachedUniverse = await fetchUniverseMapPaginated(supabase);
  cacheTimestamp = now;

  return cachedUniverse;
}
```

---

## Estimaci√≥n de Egress

### Formula Base

```
Egress (MB) = Row Count √ó Avg Row Size (bytes) / (1024 √ó 1024)
```

### Tama√±os T√≠picos por Tabla

| Tabla                  | Campos T√≠picos                 | Avg Row Size | Rows T√≠picas | Egress sin LIMIT |
| ---------------------- | ------------------------------ | ------------ | ------------ | ---------------- |
| `fintra_universe`      | ticker, sector, industry       | ~150 bytes   | 88,000       | ~13 MB           |
| `datos_financieros`    | 15 campos num√©ricos            | ~500 bytes   | 5M           | ~2.4 GB          |
| `datos_valuacion`      | ticker, date, 4 ratios         | ~200 bytes   | 20M          | ~3.8 GB          |
| `performance_windows`  | ticker, window, return, date   | ~150 bytes   | 135M         | ~19 GB           |
| `industry_performance` | industry, window, return, date | ~150 bytes   | 766k         | ~110 MB          |
| `sector_performance`   | sector, window, return, date   | ~150 bytes   | 100k         | ~14 MB           |

### C√°lculo por Ejecuci√≥n de Snapshots Bulk

```
Snapshots Bulk (53k tickers):
‚îú‚îÄ industry_performance (sin filtro): ~110 MB
‚îú‚îÄ fintra_universe (completo): ~13 MB
‚îú‚îÄ datos_financieros (530 batches √ó 100 tickers): ~5 GB
‚îú‚îÄ datos_valuacion (530 batches √ó 100 tickers): ~2 GB
‚îî‚îÄ TOTAL: ~7-8 GB

Con m√∫ltiples re-ejecuciones:
‚îî‚îÄ 6 ejecuciones √ó 7 GB = ~42 GB
```

---

## Triggers de Alerta

### üö® Alerta Cr√≠tica (>10 GB/ejecuci√≥n)

- Query sin LIMIT en tabla >1M rows
- Query con `.lte()` en tabla temporal sin LIMIT
- Select `*` en bulk queries

### ‚ö†Ô∏è Alerta Media (5-10 GB/ejecuci√≥n)

- Fetch hist√≥rico sin LIMIT expl√≠cito
- M√∫ltiples batches sin optimizar fields

### ‚ÑπÔ∏è Aceptable (<5 GB/ejecuci√≥n)

- Queries con LIMIT apropiado
- Filtros por fecha actual
- Select campos espec√≠ficos

---

## Checklist Pre-Deployment

Antes de ejecutar cualquier cron/script bulk, verificar:

- [ ] ‚úÖ Todas las queries tienen LIMIT expl√≠cito
- [ ] ‚úÖ Tablas temporales usan `.eq('date', today)` (no `.lte()`)
- [ ] ‚úÖ Select solo campos necesarios (no `*`)
- [ ] ‚úÖ Counts usan `{ head: true }`
- [ ] ‚úÖ Paginaci√≥n expl√≠cita para >1k rows esperados
- [ ] ‚úÖ Test con 10 tickers ANTES de full run
- [ ] ‚úÖ Estimaci√≥n de egress documentada
- [ ] ‚úÖ Logs incluyen row counts

---

## Tools de Monitoreo

### Script: Estimate Egress Impact

```bash
npx tsx scripts/test/estimate-egress-impact.ts
```

Output esperado:

```
üìä EGRESS PER FULL EXECUTION (53k tickers)
‚úÖ DESPU√âS (con fixes):
   - industry_performance: 0.32 MB
   - fintra_universe: 13.00 MB
   - datos_financieros: 1.20 GB
   - datos_valuacion: 0.50 GB
   üì¶ TOTAL: 1.71 GB
```

### Script: Validate Fixes

```bash
npx tsx scripts/test/validate-egress-fixes.ts
```

Valida que fixes est√©n aplicados antes de full run.

---

## Incident Response

### Si detectas spike de egress:

1. **DETENER** ejecuciones inmediatamente
2. Revisar logs de queries ejecutadas hoy
3. Identificar query(s) sin LIMIT
4. Aplicar fixes seg√∫n patterns de este doc
5. Test con subset (10 tickers)
6. Validar egress <500MB para test
7. Reanudar operaci√≥n

### Documentar Incident

Usar template: `documentacion-tecnica/BILLING_INCIDENT_YYYY-MM-DD.md`

---

## Referencias

- Supabase Pricing: https://supabase.com/pricing
- PostgREST Limits: https://postgrest.org/en/stable/api.html#limits-and-pagination
- Incident 2026-02-08: `BILLING_INCIDENT_2026-02-08.md`

---

**√öltima actualizaci√≥n:** 08 Feb 2026  
**Owner:** Dev Team  
**Review:** Mensual
