# Resumen: Gaps Cr√≠ticos de Data Pipeline Agregados a Auditor√≠a

## ‚úÖ Actualizaci√≥n Completada

Se agreg√≥ **FASE 12 completa** al script de auditor√≠a con 7 tareas cr√≠ticas para diagnosticar problemas de ejecuci√≥n de pipelines.

---

## üö® Problema Central Detectado

**"C√≥digo existe pero no se ejecuta"**

Existen 6 gaps cr√≠ticos donde:
- ‚úÖ C√≥digo implementado (archivos .ts presentes)
- ‚ùå Cron jobs activos (endpoints NO ejecut√°ndose)
- ‚ùå Datos en base de datos (campos vac√≠os o <10% cobertura)

---

## üìã Las 7 Tareas de FASE 12

### TAREA 12.1: IFS Computation Job ‚ùå CR√çTICO

**Problema:**
- C√≥digo `ifs.ts` existe
- Importado en `fgos-recompute.ts`
- Pero NO existe `/api/cron/compute-ifs`
- Campos `ifs` e `ifs_memory` vac√≠os (0% cobertura)

**Impacto:**
‚Üí IFS nunca se calcula autom√°ticamente
‚Üí Framework de 5 dimensiones incompleto

**Qu√© verifica la tarea:**
```bash
- Existe archivo ifs.ts
- Existe endpoint /api/cron/compute-ifs
- calculateIFS se invoca en alg√∫n cron
- Campos se populan en DB
```

---

### TAREA 12.2: Sector Ranking Job ‚ö†Ô∏è ALTO

**Problema:**
- Endpoint `/api/cron/compute-ranks` EXISTE
- Pero solo llama a SQL RPC: `compute_sector_ranks()`
- Si funci√≥n SQL no existe/falla ‚Üí Rankings nunca se calculan

**Impacto:**
‚Üí Rankings sectoriales sin datos
‚Üí Comparaciones relativas imposibles

**Qu√© verifica la tarea:**
```bash
- Endpoint compute-ranks existe
- Llama a RPC de Supabase
- Funci√≥n SQL existe en DB
- Funci√≥n SQL tiene l√≥gica (no vac√≠a)
```

**Requiere verificaci√≥n manual en Supabase:**
```sql
SELECT routine_name 
FROM information_schema.routines 
WHERE routine_name = 'compute_sector_ranks';
```

---

### TAREA 12.3: Relative Performance (Alpha) ‚ùå CR√çTICO

**Problema:**
- NO existe `/api/cron/sector-performance-relative`
- Existe `sector-performance-windows-aggregator` (calcula √≠ndices de sector)
- Pero falta cruce: ticker vs sector ‚Üí Alpha

**Impacto:**
‚Üí No hay medici√≥n de performance relativa
‚Üí No se puede saber si un ticker supera/underperform su sector

**Qu√© verifica la tarea:**
```bash
- Cron sector-performance-windows-aggregator existe (√≠ndices)
- Cron sector-performance-relative existe (Alpha)
- C√°lculo de Alpha implementado
- Campo performance_relative en DB poblado
```

---

### TAREA 12.4: Performance Windows Discrepancias ‚ö†Ô∏è ALTO

**Problema:**
- C√≥digo define `['1M', '3M', '6M', '1Y', '2Y', '3Y', '5Y']`
- Pero 3M/6M/2Y pueden no verse en DB (problema de ejecuci√≥n)
- 1W y YTD ausentes (comentados o no implementados)

**Impacto:**
‚Üí An√°lisis de momentum incompleto
‚Üí Comparaciones temporales limitadas

**Qu√© verifica la tarea:**
```bash
- Ventanas configuradas en c√≥digo
- Ventanas con datos en DB (query SQL)
- Discrepancias (c√≥digo vs DB)
- Ventanas comentadas/ausentes
```

**Query SQL de verificaci√≥n:**
```sql
SELECT DISTINCT jsonb_object_keys(performance_windows) 
FROM fintra_snapshots 
LIMIT 10;
```

---

### TAREA 12.5: FGOS Confidence Source ‚ö†Ô∏è MEDIO

**Problema:**
- C√≥digo usa `calculateDimensionalConfidence()` (basado en datos actuales)
- Usuario espera `calculateConfidenceLayer()` (basado en historia + volatility + universe)
- Ambas funciones existen pero se usa la menos robusta

**Impacto:**
‚Üí Confidence menos preciso
‚Üí No penaliza empresas con poca historia

**Qu√© verifica la tarea:**
```bash
- Qu√© funci√≥n se usa en FGOS
- Inputs de cada funci√≥n
- Discrepancia expectativa vs realidad
- Evaluar si cambiar o documentar
```

---

### TAREA 12.6: Sentiment/News Layer ‚ùå CR√çTICO

**Problema:**
- NO existe `/api/cron/sentiment-bulk`
- Cobertura actual: 7.55% (residual de pruebas manuales)
- Sin automatizaci√≥n activa

**Impacto:**
‚Üí Noticias no se procesan autom√°ticamente
‚Üí Narrative risk/bias no se actualiza
‚Üí Motor de noticias no funcional (92.45% sin datos)

**Qu√© verifica la tarea:**
```bash
- Cron sentiment-bulk existe
- C√≥digo news engine existe
- Integraci√≥n n8n configurada
- Campos narrative_risk/bias poblados
```

**Pipeline completo esperado:**
```
1. Cron fetch news ‚Üí FMP API
2. Por cada noticia ‚Üí Webhook n8n
3. n8n ‚Üí LLM analysis ‚Üí Structured insight
4. Cron ‚Üí Guarda insights en DB
5. Cron aggregator ‚Üí Calcula Bias/Risk
```

**Pipeline actual:**
```
‚úÖ Webhook n8n existe
‚ùå Cron fetch news NO existe
‚ùå Cron aggregator NO existe
```

---

### TAREA 12.7: Scheduling de Crons ‚ö†Ô∏è ALTO

**Problema:**
- Crons pueden existir como archivos
- Pero no estar configurados en `vercel.json`
- Sin scheduling ‚Üí Nunca se ejecutan

**Impacto:**
‚Üí Crons dormidos (c√≥digo existe pero no corre)

**Qu√© verifica la tarea:**
```bash
- vercel.json con crons configurados
- Todos los cron endpoints incluidos
- Schedules no conflictivos
- Crons faltantes en scheduling
```

**Ejemplo de problema:**
```json
// vercel.json actual
{
  "crons": [
    {
      "path": "/api/cron/snapshot",
      "schedule": "0 2 * * *"
    }
  ]
}

// Faltantes:
// - /api/cron/compute-ifs
// - /api/cron/sector-performance-relative
// - /api/cron/sentiment-bulk
```

---

## üìä Matriz de Gaps (Resumen)

| Gap | C√≥digo | Endpoint | Scheduled | DB | Severidad |
|-----|--------|----------|-----------|-----|-----------|
| **IFS Computation** | ‚úÖ | ‚ùå | ‚ùå | 0% | CR√çTICO |
| **Sector Ranks (SQL)** | ‚úÖ | ‚úÖ | ‚úÖ | ‚ö†Ô∏è | ALTO |
| **Relative Performance** | ‚ö†Ô∏è | ‚ùå | ‚ùå | 0% | CR√çTICO |
| **Windows 3M/6M/2Y** | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ALTO |
| **Windows 1W/YTD** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | MEDIO |
| **Confidence Source** | ‚úÖ | ‚úÖ | ‚úÖ | ‚ö†Ô∏è | MEDIO |
| **Sentiment/News** | ‚ö†Ô∏è | ‚ùå | ‚ùå | 7.55% | CR√çTICO |

### Impacto Acumulado

**Engines sin datos:**
- ‚ùå IFS: 0% cobertura
- ‚ùå News: 7.55% cobertura (residual)

**Engines con datos parciales:**
- ‚ö†Ô∏è Performance: Ventanas incompletas
- ‚ö†Ô∏è Sector Ranks: Depende de SQL RPC

**Engines funcionales:**
- ‚úÖ FGOS: (verificar con auditor√≠a)
- ‚úÖ Valuation: (verificar con auditor√≠a)
- ‚úÖ Life Cycle: (verificar con auditor√≠a)

---

## üéØ Priorizaci√≥n de Correcciones

### URGENTE (Esta semana)

**1. Crear /api/cron/compute-ifs** [1 d√≠a]
```typescript
// L√≥gica:
for (const ticker of tickers) {
  const ifs = await calculateIFS(ticker);
  await updateSnapshot(ticker, { ifs, ifs_memory });
}
```

**2. Crear /api/cron/sector-performance-relative** [2 d√≠as]
```typescript
// L√≥gica:
const sectorReturn = getSectorIndex(sector, window);
const tickerReturn = getTickerReturn(ticker, window);
const alpha = tickerReturn - sectorReturn;
await updateSnapshot(ticker, { performance_vs_sector: alpha });
```

**3. Completar pipeline de Sentiment** [3 d√≠as]
```typescript
// Paso 1: Crear sentiment-bulk (fetch news)
// Paso 2: POST a n8n webhook por cada noticia
// Paso 3: Crear sentiment-aggregator (Bias/Risk)
```

**4. Verificar SQL compute_sector_ranks** [4 horas]
```sql
-- Verificar existe
-- Si no, crearla
-- Probar ejecuci√≥n
```

**Total urgente:** ~7 d√≠as de trabajo

---

### ALTO (Pr√≥ximas 2 semanas)

**5. Debugging de Windows 3M/6M/2Y** [1 semana]
- Investigar por qu√© c√≥digo existe pero DB no tiene datos
- Agregar logging detallado
- Verificar parsing de FMP API
- Verificar persistencia en DB

**6. Agregar Windows 1W y YTD** [3 d√≠as]
- Descomentar o implementar
- Agregar a pipeline

**7. Clarificar Confidence Source** [2 d√≠as]
- Decidir: Dimensional vs Layer
- Implementar o documentar

---

## üìù Comandos de Verificaci√≥n R√°pida

### Verificar cobertura de campos:

```sql
-- En Supabase SQL Editor
SELECT 
  COUNT(*) as total_tickers,
  
  -- IFS
  COUNT(ifs) as ifs_present,
  ROUND(100.0 * COUNT(ifs) / COUNT(*), 2) as ifs_coverage,
  
  -- Performance relative
  COUNT(performance_vs_sector) as perf_relative_present,
  ROUND(100.0 * COUNT(performance_vs_sector) / COUNT(*), 2) as perf_relative_coverage,
  
  -- News
  COUNT(narrative_risk) as news_present,
  ROUND(100.0 * COUNT(narrative_risk) / COUNT(*), 2) as news_coverage
  
FROM fintra_snapshots;
```

### Verificar endpoints de cron:

```bash
# En terminal del proyecto
find app/api/cron -name "route.ts" | \
  sed 's|app/api/cron/||' | \
  sed 's|/route.ts||' | \
  sort
```

### Verificar scheduling:

```bash
# Ver vercel.json
cat vercel.json | grep -A 30 "cron"
```

---

## üîÑ Workflow de Correcci√≥n

### Fase 1: Crear Endpoints Faltantes (Semana 1)

**D√≠a 1-2:** compute-ifs
```bash
1. Crear /app/api/cron/compute-ifs/route.ts
2. Implementar loop con calculateIFS()
3. Agregar try-catch por ticker
4. Logs obligatorios (START, OK, FAILED)
```

**D√≠a 3-4:** sector-performance-relative
```bash
1. Crear /app/api/cron/sector-performance-relative/route.ts
2. Obtener √≠ndices de sector (de aggregator)
3. Cruzar con ticker returns
4. Calcular Alpha
5. Persistir en DB
```

**D√≠a 5:** sentiment-bulk + aggregator
```bash
1. Crear /app/api/cron/sentiment-bulk/route.ts
2. Fetch news de FMP
3. POST a n8n webhook
4. Guardar insights
5. Crear sentiment-aggregator para Bias/Risk
```

---

### Fase 2: Configurar Scheduling (Semana 1)

```json
// Actualizar vercel.json
{
  "crons": [
    {
      "path": "/api/cron/snapshot",
      "schedule": "0 2 * * *"
    },
    {
      "path": "/api/cron/compute-ifs",
      "schedule": "0 3 * * *"
    },
    {
      "path": "/api/cron/sector-performance-relative",
      "schedule": "0 4 * * *"
    },
    {
      "path": "/api/cron/sentiment-bulk",
      "schedule": "0 5 * * *"
    },
    {
      "path": "/api/cron/sentiment-aggregator",
      "schedule": "0 6 * * *"
    }
  ]
}
```

---

### Fase 3: Validar Ejecuci√≥n (Semana 2)

**D√≠a 1-2:** Ejecutar manualmente cada cron
```bash
# Trigger manual via URL
curl https://tu-dominio.vercel.app/api/cron/compute-ifs?secret=XXX

# Verificar logs en Vercel
# Verificar DB en Supabase
```

**D√≠a 3-4:** Verificar cobertura
```sql
-- Ejecutar queries de verificaci√≥n
-- Medir cobertura antes/despu√©s
```

**D√≠a 5:** Generar reporte
```
Cobertura inicial:
- IFS: 0% ‚Üí 90%+
- Performance Relative: 0% ‚Üí 95%+
- News: 7.55% ‚Üí 85%+
```

---

## ‚úÖ Checklist de Validaci√≥n Post-Correcci√≥n

Despu√©s de implementar todos los fixes, ejecutar:

### [ ] Verificar endpoints existen
```bash
find app/api/cron -name "route.ts" | wc -l
# Debe ser >= 7 (snapshot + ifs + relative + sentiment-bulk + aggregator + ranks + performance-windows)
```

### [ ] Verificar scheduling configurado
```bash
cat vercel.json | grep -c "path.*cron"
# Debe coincidir con n√∫mero de endpoints
```

### [ ] Verificar SQL functions
```sql
SELECT routine_name 
FROM information_schema.routines 
WHERE routine_name LIKE '%compute%';
```

### [ ] Verificar cobertura en DB
```sql
-- Query de cobertura completa (ver arriba)
-- Target: >85% en todos los campos
```

### [ ] Ejecutar auditor√≠a completa nuevamente
```bash
# Pasar script completo a Claude Code
# Verificar que todos los ‚úÖ est√©n verdes
```

---

## üìà M√©tricas de √âxito

**ANTES (estado actual):**
- IFS coverage: 0%
- Performance Relative coverage: 0%
- News coverage: 7.55%
- Pipelines activos: 3-4 de 7

**DESPU√âS (target):**
- IFS coverage: >90%
- Performance Relative coverage: >95%
- News coverage: >85%
- Pipelines activos: 7 de 7

**Timeline:**
- Semana 1: Implementaci√≥n de endpoints + scheduling
- Semana 2: Validaci√≥n + debugging
- Semana 3: Re-auditor√≠a + ajustes finales

**Inversi√≥n:** ~3 semanas de 1 desarrollador

---

## üéì Lecciones Aprendidas

### Problema Arquitectural Detectado

**"C√≥digo desconectado de ejecuci√≥n"**

Causas:
1. C√≥digo implementado pero no "wired up" (sin endpoint)
2. Endpoints creados pero no scheduled (sin vercel.json)
3. SQL functions invocadas pero nunca creadas
4. Crons ejecut√°ndose pero fallando silenciosamente (sin logs)

### Prevenci√≥n Futura

**Checklist para nuevos features:**
1. ‚úÖ Implementar l√≥gica (lib/engine/)
2. ‚úÖ Crear endpoint (app/api/cron/)
3. ‚úÖ Agregar a scheduling (vercel.json)
4. ‚úÖ Crear SQL functions si necesario
5. ‚úÖ Agregar logs obligatorios
6. ‚úÖ Ejecutar manualmente y verificar
7. ‚úÖ Verificar cobertura en DB
8. ‚úÖ Documentar en auditor√≠a

---

## üîó Integraci√≥n con Auditor√≠a Principal

Esta FASE 12 se agreg√≥ al archivo:
**AUDITORIA-ENGINES-FINTRA.md**

Ubicaci√≥n en el script:
- FASE 1-11: Auditor√≠a de metodolog√≠a (c√≥digo)
- **FASE 12: Auditor√≠a de pipelines (ejecuci√≥n)** ‚Üê NUEVA
- FASE 13: Reporte final consolidado

El reporte final ahora incluye:
- ‚úÖ Cumplimiento de metodolog√≠a
- ‚úÖ Infracciones de c√≥digo
- ‚úÖ **Gaps de pipeline** ‚Üê NUEVO
- ‚úÖ Matriz de impacto
- ‚úÖ Plan de acci√≥n priorizado

---

## üöÄ Pr√≥ximo Paso

**Ejecutar auditor√≠a completa con Claude Code:**

```bash
cd /path/to/fintra
claude-code chat
```

```
Audita Fintra usando el script AUDITORIA-ENGINES-FINTRA.md

Ejecuta TODAS las fases (1-13) incluyendo la nueva FASE 12 
de data pipeline gaps.

Genera reporte completo con:
1. Cumplimiento de metodolog√≠a
2. Infracciones de c√≥digo
3. Gaps de pipeline (CR√çTICO)
4. Plan de acci√≥n priorizado

Enf√≥cate especialmente en FASE 12 para diagnosticar 
por qu√© IFS, Performance Relative y News no tienen datos.
```

**Tiempo estimado:** 3-4 horas de auditor√≠a autom√°tica

**Output esperado:**
- Reporte markdown completo
- C√≥digo de correcci√≥n para cada gap
- Plan de implementaci√≥n priorizado
- Timeline de 3 semanas para restaurar pipelines

---

**CR√çTICO:** No implementes Sprint Plan de mejoras hasta completar esta auditor√≠a y corregir gaps de pipeline. Sin datos, las mejoras son in√∫tiles.
